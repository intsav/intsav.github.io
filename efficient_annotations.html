<!DOCTYPE html>
<html lang="en">

<!-- ======= Head Section - DON'T CHANGE ======= -->
<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <title>Effecient Annotations</title>
  <link href="assets\img\Tricuspid.PNG" rel="icon">
  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">
  <!-- Vendor CSS Files -->
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/remixicon/remixicon.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">
  <!-- Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">
</head>

<!-- ======= Body Section ======= -->
<body>
  <!-- ======= Navigation Bar - DON'T CHANGE ======= -->
  <header id="header" class="fixed-top">
    <div class="container d-flex align-items-center justify-content-between">
      <a href="index.html" class="logo"><img src="assets/img/logo.png" alt="" class="img-fluid"></a>
      <nav id="navbar" class="navbar">
        <ul>
          <li><a class="nav-link scrollto" href="index.html">Home</a></li>
          <li><a class="nav-link scrollto" href="index.html#projects">Projects</a></li>
          <li><a class="nav-link scrollto" href="index.html#team">People</a></li>
          <li><a class="nav-link scrollto" href="index.html#resources">Resources</a></li>
          <li><a class="nav-link scrollto" href="index.html#funding">Funding</a></li>
          <li><a class="nav-link scrollto" href="index.html#partners">Partners</a></li>
          <li><a class="nav-link scrollto" href="index.html#workwithus">Vacancies</a></li>
          <li><a class="nav-link scrollto" href="index.html#contact">Contact</a></li>
        </ul>
        <i class="bi bi-list mobile-nav-toggle"></i>
      </nav>
    </div>
  </header><!-- End Navigation Bar -->

    <!-- ======= Title Section ======= -->
    <section id="project-title" class="d-flex align-items-center">
      <div class="container position-relative" data-aos="fade-up" data-aos-delay="100">
        <div class="row">
          <div class="col-12 text-left">
            <h1>Active Learning for creating a Biobank of expert annotations in Echocardiography</h1>
          <!--  <h2><i> Eman Alajrami <sup>1</sup>, Elisabeth S Lane <sup>1</sup>, Jevgeni Jevsikov <sup>1</sup>, James P Howard <sup>2</sup>, Matthew J Shun-shin <sup>2</sup>, Graham D Cole <sup>2</sup>, Darrel P Francis <sup>2</sup>, Massoud Zolgharni <sup>1,2</sup><i></h2>
              <h3><sup>1</sup> School of Computing and Engineering, University of West London, London, United Kingdom<h3>
              <h3><sup>2</sup> National Heart and Lung Institute, Imperial College, London, United Kingdom<h3> -->
            </div>
          </div>
        </div>

    </section><!-- End Title -->

    <!-- Main Webpage Section -->
  <main id="project-main">

    <!-- ======= Project Body Section ======= -->
    <section id="project-body">

      <!-- ======= Project Introduction ======= -->
      <div class="project-intro">
        <div class="container">
          <div class="row justify-content-left">
            <div class="col-12">
                  <div align="justify">
              <hr>
              <h1><b>Introduction </b> </h1>
              <br>
              <h3> This project addresses the challenge of scarce annotations; using deep learning and active learning (AL) techniques to reduce annotation costs and efforts while maintaining high segmentation accuracy and improving clinical workflow efficiency.
              </h3>
              <h3> This work presents several AL methods, contributing to the cost-effective medical image annotation. The first project comprehensively evaluates existing AL approaches, establishing a valuable baseline for comparing different strategies. The second project explores ensemble-based AL techniques, leveraging different loss functions and uncertainty scoring methods. In the third project, a novel semi-supervised active learning method is developed, combining pseudo-labels from model predictions with expert annotations. The final project introduces an optimised clustering method using Fuzzy C-means for diversity sampling. </h3>
              <h3> The outcome of the AL study was utilised to create a biobank of echo images for several projects to rank images and videos based on diversity. This method ensures that clinicians focus on labelling the images that will most effectively improve the AI model's performance, reducing the overall number of images that need to be annotated.</h3>
                </div>
          </div>
        </div>

          </div>
        </div>

      <!-- ======= Project Dataset ======= -->
      <div class = "project-dataset">
        <div class="container project-container">
          <div class="row justify-content-left">
            <div class="col-12 col-md-12 col-lg-6 col-xl-6">

            <figure>
              <img class="img-fluid" src="assets\img\projects\Efficient_Annotations\Sample_image.png" alt="Annotation" >
              <div class="caption" >Fig. 1 A Sample image from the Unity dataset</div>
            <!--  <figcaption>Fig. 1 A Sample image from the Unity dataset</figcaption> -->
            </figure>

            </div>
            <div class="col-6 col-md-6 col-lg-6 col-xl-6">
                <div align="justify">
              <h2><b>Dataset</b></h2>
              <h3>Three different datasets of cardiac imaging are used for our experiments:
                the CAMUS dataset, the Unity dataset, and the consensus testing dataset.<br><br>
                <b>CAMUS dataset</b> is a public, fully annotated dataset for 2D echocardiographic assessment. view sequences. <br>
                  All the details of the CAMUS dataset are available on the official website (https://www.creatis.insa-lyon.fr/Challenge/camus/index.html).


                <br><br>
                <b>Unity dataset</b>is a private dataset extracted from 1224 videos of the apical four-chamber echocardiographic view retrieved
                from Imperial College Healthcare NHS Trust's echocardiogram database.
                The images are obtained using ultrasound equipment from GE and Philips manufacturers.
                The acquisition of these images is ethically approved by the Health Regulatory Agency
                (Integrated Research Application System identifier 243023).<br><br>
                It contains 2800 images sampled from different points in the cardiac cycle and labelled by a pool of
                experts using our in-house online labelling platform (https://unityimaging.net).
                This dataset was used for model developments (i.e., training and validation) and split into 70% for training, 15% for validation and 15% for testing.
                <br><br>

                <b>Consensus dataset:</b> It was utilised for the testing and was curated from a series of investigations conducted over three working days in 2019, years away from the development dataset. The testing dataset consisted of 100 A4C videos, from which 200 end-diastolic and end-systolic frames were selected automatically using a previously developed model. 11 human experts labelled each image using the same platform, mutually blinded to the labels of the others. The average of these 11 annotations was used for each image to create its GT. This provided high-quality consensus reference annotations, which served as a uniquely robust and representative benchmark for performance evaluations.
                  </h3>
              <br>
            </div>

            </div>
          </div>
        </div>
      </div>
        <!-- ======= Project Architecture ======= -->
      <div class = "project-architecture">

          <div class="container">
            <hr>
            <div class="row justify-content-left">
              <div class="col-12">
              <h2><b>Network Architecture</b></h2>
            </div>
              <div class="col-12 col-md-12 col-lg-6 col-xl-6">
                <div align="justify">
                  <h3><br><br>The network architecture utilised in this study is the Monte Carlo dropout (MCD) U-Net with a depth of 5, designed explicitly for Bayesian AL in LV segmentation tasks. The overall architecture is depicted in the above figure. This architecture integrates dropout layers throughout the network to facilitate MCD for uncertainty estimation. The MCD U-Net was used as the baseline model for all of the following studies.
                   </h3>
                 </div>
                </div>
                <div class="col-12 col-md-12 col-lg-6 col-xl-6">

                     <img class="img-fluid" src="assets\img\projects\Efficient_Annotations\Unet_no_num.jpeg" alt="IMAGE PLACEHOLDER" >
                     <div class="caption" >Fig. 2 The customised Bayesian U-Net architecture</div>
                    <!-- <figcaption>        Fig. 2 The customised Bayesian U-Net architecture </figcaption> -->

                </div>
              </div>
            </div>
          </div>

        <!-- ======= Project Implementation ======= -->
        <div class = "project-implementation">
          <div class="container">
            <hr>
            <div class="row justify-content-left">
              <div class="col-12">
                <div align="justify">
              <!--  <hr> -->
                <h2>Implementation</h2>
                <h3>A standard Active Learning (AL) methodology is applied throughout,  encompassing four steps: training the
                  U-Net model on the initial annotated data (L),
                  calculating the model uncertainty scores or representativeness scores on the unlabeled pool of data (U),
                  selecting the top-ranked batch of images (K) to obtain their labels from oracle and add them to L and remove
                   them from U, and finally retrain the model on the updated L.
                   These steps are repeated until the optimal number of AL iterations is reached. <br>
                   Random sampling and a variety of different selective sampling approaches are used for
                   selecting the next batch of images from the unlabelled pool.
                   The most common AL selection strategy is uncertainty sampling, where the most uncertain unlabelled images are
                   quiried for annotation. Such uncertainty methods include: Classification Uncertainty (Pixel-wise), Predictive entropy,
                   and Monte Carlo droupout ensemble-based methods using entropy, variance (Var), variation ratio (Var_ratio),
                   standard diviation (STD), Coeffcient of variation (Coef_var),
                   and Bayesian active learning with disagreement (BALD).<br><br>
                   <b> Training settings: </b> Tensorflow and Keras frameworks are used for the development of DL models, and training was conducted using an Nvidia RTX3090 GPU. U-Net was trained using binary cross-entropy loss and ADAM optimiser with a learning rate of 0.0001 for 200 epochs. Images were resized to 512x512, and a fixed batch size of 8 was applied.
                  For small datasets A and B, we selected 10% of the initial training data as L, and U will be the remaining 90%.
                  For the larger dataset, we chose 4% as the initial L, and the remaining is for the U, which will be
                  used as an oracle. Finally, to have a fair comparison between methods, we trained the model on the
                  initially labelled data of
                  the three datasets and used the same model's weights for training the following AL iterations.</h3>


                </div>
              </div>
            </div>
          </div>
        </div>
      <!-- ======= Project Evaluation ======= -->
      <div class = "project-evaluation">
        <div class="container align-middle">

          <div class="row">

            <!-- <div class="col-12 col-lg-6 col-md-6 text-center">
            < <img class="img-fluid" src="" alt="IMAGE PLACEHOLDER">
            </div> -->

            <div class="row justify-content-left">
              <div class="col-12">
                <hr>
                <h2>Evaluation</h2>
                <div align="justify">
                <h3>We evaluated the model after every AL iteration using the Dice-Coefficient (DC) metric,
                  and it is computed between the ground truth and the inferred prediction for each image in
                  the testing dataset. Then the mean of Dice scores of all images is calculated to present the
                  model's accuracy. Each AL selection strategy is trained three times,
                  and the average of the DC at each AL iteration is computed and used to plot the results. </h3>
                </div>
                <div class="text-left">
                  <br>
                <!--  <a class="btn btn-primary" href="" role="button">Download the code</a>-->
                </div>
              </div>
            </div>

          </div>
        </div>
      </div>

      <!-- ======= Project Results ======= -->

      <div class = "project-results">
        <div class="container">
          <hr>
          <div class="row justify-content-left">
            <div class="col-12 col-md-12 col-lg-6 col-xl-6">


              <img class="img-fluid" src="assets\img\projects\Efficient_Annotations\Merge_unc_5.jpg" alt="IMAGE PLACEHOLDER">
              <div class="caption" >Fig. 3 Active learning performance on CAMUS and Unity datasets</div>
            <!--  <figcaption> Fig. 3 Active learning performance on CAMUS and Unity datasets</figcaption> -->


            </div>
            <div class="col-6 col-md-6 col-lg-6 col-xl-6">
                <div align="justify">
              <h2><b>Results: </b></h2>
              <div align="justify">

              <h3>Fig. 3 shows the performance of uncertainty sampling techniques compared to random selection on CAMUS and Unity datasets.
                The horizontal black dashed line presents the performance of the entire labelled dataset. Our experiments show that the predictive Entropy is the best uncertainty strategy compared
                to others on CAMUS and Unity datasets (see Fig. 3). For example, the predictive Entropy achieved 97.7% of the
                entire dataset performance on CAMUS using 25% of the annotated dataset. At the same time,
                the other policies ( BALD, Var, Var-ratio, Coef-var, STD, pixel-wise) required approximately
                35% to approach that performance. Thus, it reduced the annotation cost by 10% to get
                that performance. Moreover, it kept converging to the maximum performance achieving 98%
                and 99% of the whole dataset performance using 35% and 40% of labels, respectively. <br>
              Coef-Var achieved 98% of the entire dataset performance on the CAMUS dataset using 40%
              of the annotations, outperforming random,pixel-wise and MDC-Entropy methods and almost
              performing similarly to other methods. After using 60% of the labels, Predictive Entropy,
              Coef-Var, Var-ratio, and BALD converged to the maximum performance outperforming other
              selection policies.
              For the Unity dataset, the predictive Entropy significantly outperformed all the other
              methods from the early stages of AL achieving 98.3% and ~ 99% of the entire dataset performance
              using only 7% and 20%  of the labels, respectively. At the same time, Coef-Var, pixel-wise, Var-ratio,
              Var and BALD needed 15% of the annotation to get 98% of the maximum performance. After using 27% of
              the annotations. Pixel-wise almost converged to the ultimate performance outperforming all other
              uncertainty techniques.  <br><br>
              Out experiments shows that most MCD ensemble methods usually do not converge till the end, such as
              Var, BALD and Var-ratio. However, some of them perform well at the early AL stages. In addition,
              our investigations show that our newly added method, Coef-Var, can perform well for some datasets.
              Thus, we recommend adding it to the heuristic uncertainty selection strategies when using ensemble techniques.  <br>
              Our experiments demonstrate the performance of various uncertainty sampling strategies varies
              amongst different datasets from the same domain.
              </h3>
              </div>


            </div>

            </div>
          </div>
        </div>
      </div>

              <div class="container">
                <hr>

                  <div class="row justify-content-left">
                    <div class="col-12">
                      <div class="text-left">
                        <h1> <b> Project Team <b></h1> <br>
                          <h6> <a href="https://www.uwl.ac.uk/staff/massoud-zolgharni" target="_blank" rel="noopener noreferrer"> Professor Massoud Zolgharni  </a></h6>
                          <h6> <a href="https://www.uwl.ac.uk/staff/nasim-dadashi-serej" target="_blank" rel="noopener noreferrer"> Dr Nasim Dadashi Serej  </a></h6>
                          <h6> <a href="https://www.researchgate.net/profile/Eman-Alajrami" target="_blank" rel="noopener noreferrer"> Dr Eman Alajrami </a> </h6>
                          <h6>  <a href="https://twitter.com/intsav_?lang=en-gb" target="_blank" rel="noopener noreferrer"> Dr Jevgeni Jevsikov</a></h6>
                          

                      </div>
                    </div>
                  </div>

                </div>

          <div class="container">
            <hr>

              <div class="row justify-content-left">
                <div class="col-12">
                  <div class="text-left">
                    <h1>  <b> References </b></h1><br>
                      <h6>  <a href="https://www.sciencedirect.com/science/article/pii/S016926072400107X" target="_blank" rel="noopener noreferrer"></a></h6>
                      <h6>  <a href="https://www.pure.ed.ac.uk/ws/portalfiles/portal/409667993/9782832512319_1_.PDF#page=103" target="_blank" rel="noopener noreferrer"></a></h6>
                      <h6>  <a href="https://openreview.net/pdf?id=g9T6yLuMJR" target="_blank" rel="noopener noreferrer"></a></h6>

                    

                  </div>
                </div>
              </div>

            </div>

          </section> <!-- End project-body -->

      </main> <!-- End #main -->

  <!-- ======= Footer - DONT CHANGE ======= -->
  <footer id="footer">



    <div class="container d-md-flex py-4">

      <div class="me-md-auto text-center text-md-start">
        <div class="copyright">
          &copy; Copyright <strong><span>IntSaV</span></strong>. All Rights Reserved
        </div>

      </div>
      <div class="social-links text-center text-md-right pt-3 pt-md-0">
        <a href="#" class="twitter"><i class="bx bxl-twitter"></i></a>
        <a href="#" class="facebook"><i class="bx bxl-facebook"></i></a>
        <a href="#" class="instagram"><i class="bx bxl-instagram"></i></a>
        <a href="#" class="google-plus"><i class="bx bxl-skype"></i></a>
        <a href="#" class="linkedin"><i class="bx bxl-linkedin"></i></a>
      </div>
    </div>
  </footer><!-- End Footer -->

  <div id="preloader"></div>
  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/purecounter/purecounter.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
