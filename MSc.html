<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0" name="viewport">
    <title>MSc Projects</title>
    <link href="assets/img/projects/Portfolio/CV/eye.png" rel="icon">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">
    <link href="assets/vendor/aos/aos.css" rel="stylesheet">
    <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
    <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
    <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
    <link href="assets/vendor/remixicon/remixicon.css" rel="stylesheet">
    <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">
    <link href="assets/css/style.css" rel="stylesheet">
    <style>
        .btn-get-started-custom {
            padding: 15px 30px;
            background-color: #007bff;
            color: white;
            border-radius: 10px;
            text-decoration: none;
            margin-bottom: 20px;
            font-size: 20px;
        }

        .project-img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 0 auto;
        }
    </style>
</head>

<!-- ======= Body Section ======= -->
<body>
  <!-- ======= Navigation Bar - DON'T CHANGE ======= -->
  <header id="header" class="fixed-top">
    <div class="container d-flex align-items-center justify-content-between">
      <a href="index.html" class="logo"><img src="assets/img/logo.png" alt="" class="img-fluid"></a>
      <nav id="navbar" class="navbar">
        <ul>
          <li><a class="nav-link scrollto" href="">Home</a></li>
          <li><a class="nav-link scrollto" href="#footer">Contact</a></li>
        </ul>
        <i class="bi bi-list mobile-nav-toggle"></i>
      </nav>
    </div>
  </header><!-- End Navigation Bar -->

    <!-- ======= Title Section ======= -->
    <section id="project-title" class="d-flex align-items-center">
      <div class="container position-relative" data-aos="fade-up" data-aos-delay="100">
        <div class="row">
          <div class="col-12 text-center">
            <h1>MSc Projects</h1>

            </div>
          </div>
        </div>
    </section><!-- End Title -->

    <!-- Main Webpage Section -->
  <main id="project-main">

    <!-- ======= Project Body Section ======= -->
    <section id="project-body">





        <!-- ======= Project 3 ======= -->

        <div class = "project-3">
          <div class="container project-container">
            <div class="row justify-content-left d-flex flex-wrap align-items-center">
              <div class="row justify-content-left">
                <div class="col-12">
                  <div align="justify">
                     <h2 style="color:blue;"><b>Project 3: Echocardiography View Classification</b></h2> <br>
                <h3>
                  In echocardiography, many canonical view types are possible,
                  each displaying distinct aspects of the heart's complex anatomy.
                  As part of routine clinical care, when images are taken the sonographer is intentionally
                  capturing a specific view, but the annotation of the view type is not applied to the image or recorded in
                  the electronic record. Thus, from raw data alone it is difficult to focus on a specific anatomical view of
                  interest.

                <ul>
                  <li>Use TMED-1 to make 3 possible view-type labels available: PLAX, PSAX,
                    or other (meaning something else other than PLAX or PSAX).<br>
                  </li>
                  <li>Use TMED-2 to find the following classes: PLAX, PSAX, A2C, A4C, or Other <br>
                    </li>
                    <li>Report the train, validation and test results. Justify your classification results on test dataset by using AUC of ROC curve.
                    Also provide the relevant performance metrics such sensitivity, etc.</li>

                </ul>
              </h3>
            </div>
          </div>
        </div>

        <div class="row justify-content-left">
          <div class="col-12 col-md-12 col-lg-6 col-xl-6" >
            <div align="center">

               <img class="img-fluid" src="assets\img\projects\Portfolio\MSc\Project3.JPG" width = "100% "  height=" 100%"  alt="IMAGE Dataset">

          </div>
        </div>
          <div class="col-12 col-md-12 col-lg-6 col-xl-6">
            <div align="Justify">
              <h3>
              <br><br>  <b>Dataset Specifications:</b>
                The TMED dataset contains transthoracic echocardiogram (TTE) imagery acquired in the course of
                routine care consistent with American Society of Echocardiography (ASE) guidelines,
                all obtained from 2011-2020 at Tufts Medical Center.
<br>TMED-1 :  set: 260 patients
<br>TMED-2 :  set: 577 patients <br><br>

  Download the dataset from the link below:<br>

  <a href="https://tmed.cs.tufts.edu/data_access.html" target="_blank" rel="noopener noreferrer">Data Access | Tufts Medical Echocardiogram Dataset (TMED)</a>
  <br><br>
  <b>Research Papers: </b><br>
  Neda Azarmehr, Xujiong Ye, James P. Howard, Elisabeth S. Lane, Robert Labs, Matthew J. Shun-Shin,
   Graham D. Cole, Luc Bidaut, Darrel P. Francis, Massoud Zolgharni, "Neural architecture search of
   echocardiography view classifiers," J. Med. Imag. 8(3) 034002 (22 June 2021).<br>
<br>  Zhe Huang, Gary Long, Benjamin Wessler, and Michael C. Hughes”A New Semi-supervised Learning Benchmark for Classifying View and Diagnosing Aortic Stenosis from Echocardiograms,”In Proceedings of the 6th Machine Learning for Healthcare (MLHC) conference, 2021.
</h3>


          </div>
          </div>
        </div>

    </div>
      <hr>
  </div>
  </div>





<!-- ======= Project 6 ======= -->

<div class = "project-6">
  <div class="container project-container">
    <div class="row justify-content-left d-flex flex-wrap align-items-center">
      <div class="row justify-content-left">
        <div class="col-12">
          <div align="justify">
             <h2 style="color:blue;"><b>Project 6: Right/ Left ventricular Segmentation in Echocardiography dataset</b></h2> <br>
        <h3>
           The segmentation of Left Ventricle (LV) is currently carried out manually by the experts,
           and the automation of this process has proved challenging due to the presence of speckle noise and the
           inherently poor quality of the ultrasound images. The CAMUS dataset, containing 2D apical four-chamber
            and two-chamber view sequences acquired from 500 patients.
           The endocardium and epicardium of the left ventricle and left atrium wall are contoured by experts.
        <ul>
          <li>Segment the left ventricle endocardium (LVEndo), the myocardium (epicardium contour more specifically, named LVEpi) and the left atrium (LA), Report the train,
            validation and test results. Also provide the relevant performance metrics.<br>

          </li>


        </ul>
      </h3>
    </div>
  </div>
</div>

<div class="row justify-content-left">
  <div class="col-12 col-md-12 col-lg-6 col-xl-6" >
    <div align="Justify">
      <h3>
      <br><br>  <b>Dataset Specifications:</b> <br><br>
      The overall CAMUS dataset consists of clinical exams from 500 patients and comprises : i) a training set of 450 patients along with the corresponding manual references based on the analysis of one clinical expert; ii) a testing set composed of 50 new patients.
      The raw input images are provided through the raw/mhd file format.
<br><br>
Download the dataset from the link below:<br>
    <a href="https://humanheart-project.creatis.insa-lyon.fr/database/" target="_blank" rel="noopener noreferrer">Human Heart Project (insa-lyon.fr) </a>
<br><br>  <b>Research Papers: </b><br>
Azarmehr, N., Ye, X., Sacchi, S., Howard, J.P., Francis, D.P., Zolgharni, M. (2020). Segmentation of Left Ventricle in 2D Echocardiography Using Deep Learning, Medical Image Understanding and Analysis. MIUA 2019.
<br>S. Leclerc et al., "Deep Learning for Segmentation Using an Open Large-Scale Dataset in 2D Echocardiography," in IEEE Transactions on Medical Imaging, vol. 38, no. 9, pp. 2198-2210, Sept. 2019, doi: 10.1109/TMI.2019.2900516

      </h3>


    </div>
</div>
  <div class="col-12 col-md-12 col-lg-6 col-xl-6">
    <div align="center">
        <br><br><br>
       <img class="img-fluid" src="assets\img\projects\Portfolio\MSc\proj6.JPG" width = "100% "  height=" 100%"  alt="IMAGE Dataset">

    </div>
  </div>
</div>

</div>
<hr>
</div>
</div>







<!-- ======= Project 9 ======= -->

<div class = "project-9">
  <div class="container project-container">
    <div class="row justify-content-left d-flex flex-wrap align-items-center">
      <div class="row justify-content-left">
        <div class="col-12">
          <div align="justify">
             <h2 style="color:blue;"><b>Project 9: Early Myocardial Infarction Detection over Multi-view Echocardiography</b></h2> <br>
        <h3>
          Myocardial infarction (MI) is the leading cause of mortality in the world that occurs
          due to a blockage of the coronary arteries feeding the myocardium. An early diagnosis
          of MI and its localization can mitigate the extent of myocardial damage by facilitating early
          therapeutic interventions. HMC-QU dataset is the first publicly shared dataset serving myocardial
          infarction detection on the left ventricle wall. The dataset includes a collection of apical 4-chamber
          (A4C) and apical 2-chamber (A2C) view 2D-echocardiography recordings.
        <ul>
          <li>Propose a method to detect MI over:
              <ul> <li>Single-view echocardiography by using the information extracted from A4C or A2C views. </li>
                  <li>Multi-view echocardiography by merging the information from A4C or A2C views.</li>
                </ul>

          </li> <br>
          <li>Report the train, validation and test results. Also provide the relevant performance metrics.</li>
        </ul>
      </h3>
    </div>
  </div>
</div>

<div class="row justify-content-left">
  <div class="col-12 col-md-12 col-lg-6 col-xl-6" >
    <div align="center">
        <br><br><br><br><br>
       <img class="img-fluid" src="assets\img\projects\Portfolio\MSc\proj9.JPG" width = "100% "  height=" 100%"  alt="IMAGE Dataset">

  </div>
</div>
  <div class="col-12 col-md-12 col-lg-6 col-xl-6">
    <div align="Justify">
      <h3>
        <br> <br> <b>Dataset Specifications:</b> <br><br>
        The dataset includes a collection of apical 4-chamber (A4C) and apical 2-chamber (A2C) view 2D
        echocardiography recordings obtained during the years 2018 and 2019. The echocardiography recordings are acquired via devices from different vendors that are Phillips and GE Vivid (GE-Health-USA) ultrasound machines. The temporal resolution (frame rate per second) of the echocardiography recordings is 25 fps. The spatial resolution varies from 422x636 to 768x1024 pixels.
  The dataset consists of 162 A4C view 2D echocardiography recordings.
  <br>The A4C view recordings belong to 93 MI patients (all first-time and acute MI) and 69 non-MI subjects.
  The dataset consists of 130 A2C view 2D echocardiography recordings that belong to 68 MI patients and 62 non-MI subjects.

<br><br>Download the dataset from the link below:<br>

<a href="https://www.kaggle.com/datasets/aysendegerli/hmcqu-dataset?select=LV+Ground-truth+Segmentation+Masks" target="_blank" rel="noopener noreferrer">HMC-QU Dataset | Kaggle</a>
<br><br>
<b>Research Papers: </b>
Degerli, M. Zabihi, S. Kiranyaz, T. Hamid, R. Mazhar, R. Hamila, and M. Gabbouj, "Early Detection of Myocardial Infarction in Low-Quality Echocardiography," in IEEE Access, vol. 9, pp. 34442-34453, 2021, https://doi.org/10.1109/ACCESS.2021.3059595.
<br><br>S. Kiranyaz, A. Degerli, T. Hamid, R. Mazhar, R. E. F. Ahmed, R. Abouhasera, M. Zabihi, J. Malik, R. Hamila, and M. Gabbouj, "Left Ventricular Wall Motion Estimation by Active Polynomials for Acute Myocardial Infarction Detection," in IEEE Access, vol. 8, pp. 210301-210317, 2020, https://doi.org/10.1109/ACCESS.2020.3038743.


  </div>
  </div>
</div>

</div>
<hr>
</div>
</div>

      
<!-- ======= Project 10 ======= -->

<div class = "project-6">
  <div class="container project-container">
    <div class="row justify-content-left d-flex flex-wrap align-items-center">
      <div class="row justify-content-left">
        <div class="col-12">
          <div align="justify">
             <h2 style="color:blue;"><b>Project 10: Doppler Mitral inflow echocardiographic_ pixel to velocity</b></h2> <br>
        <h3>
          The project involves working with Doppler Mitral inflow echocardiographic images. The images show measurements of the blood flow velocity.
          Currently,  AI models can detect and measure necessary parameters on Mitral echocardiographic images,  but measurements are acquired in pixel values, while in order to adapt the techniques to real-world scenario,
           automated measurements should be converted to velocity values. <br><br>
          Usually, there is no way of getting the pixel-to-velocity conversion rate apart from the images themself.
          Echocardiographic images contain velocity values, as well as the 0-line, so the project requires student to create a deployable model that will process echocardiographic images and will lead to pixel-to-velocity conversion rate.
          Student is free to use any available computer vision techniques,
          as long as they can be deployed and incorporated into a larger Deep Learning pipeline. <br><br>

          Student will also be able to have some initial consultation with members of IntSav team,  and will work at the AI-lab.
      </h3>
      <div align="center">
          <br><br>
         <img class="img-fluid" src="assets\img\projects\Portfolio\MSc\MI.jpeg"   alt="IMAGE Dataset">

      </div>

    </div>
  </div>
</div>
</div>
<hr>
</div>
</div>


<!-- ======= Project 11 ======= -->

<div class = "project-6">
  <div class="container project-container">
    <div class="row justify-content-left d-flex flex-wrap align-items-center">
      <div class="row justify-content-left">
        <div class="col-12">
          <div align="justify">
             <h2 style="color:blue;"><b>Project 11: Advanced Optimization of Convolutional Neural Networks for Echocardiographic 
               Image Analysis using Automated Hyperparameter Tuning</b></h2> <br>
            
        <h3><b>Introduction:</b><br><br>
          In the field of medical imaging, particularly echocardiography, Convolutional Neural Networks (CNNs) have shown promising 
          potential to enhance diagnostic processes through accurate image classification and segmentation. However, the optimal 
          performance of CNN models is dependent on the precise tuning of hyperparameters, a task that is traditionally time-consuming 
          and requires extensive experiments. This project proposes the use of automated hyperparameter optimization (HPO) techniques to 
          streamline the optimization process, aiming to improve the efficiency and accuracy of CNN models for echocardiographic analysis. 
          By leveraging advanced HPO methods and tools such as Keras Tuner and Optuna, the project seeks to eliminate the manual tuning bottleneck, 
          fostering advancements in automated medical diagnostics.<br><br>
         
        <b>Aims:</b><br><br>
        <ol>
          <li>To review and assess the current landscape of CNN architectures and HPO techniques, focusing on their applications and 
            performance in medical imaging, specifically echocardiography.</li>
          <li>To implement and evaluate automated HPO strategies to enhance 
            CNN models for echocardiographic view classification and image segmentation, comparing their effectiveness against traditional manual tuning methods.</li>
        </ol><br>
        <b>Significance:</b><br><br>
         This project aims to significantly advance echocardiographic analysis by automating CNN model optimization, 
         enhancing clinical diagnostics and making advanced AI tools more accessible to medical applications and researchers.
          <br><br>
        <b>Implementation and Datasets:</b><br><br>
         You can implement automated hyperparameter tuning for the following tasks: <br><br>
          <ol>
          <li>Echocardiography View classification using the description and dataset in Project 3.</li>
          <li>Left ventricular Segmentation in Echocardiography using the description and dataset in Project 6.</li>
        </ol></h3>
      <div align="center">
          <br/>
         <img class="img-fluid" src="assets\img\projects\Portfolio\MSc\proj11.jpeg"   alt="Tuner Search Loop">

      </div>

    </div>
  </div>
</div>
</div>
<hr>
</div>
</div>

      
    <!--  <div class = "project-2">

          <div class="container">
            <hr>
            <div class="row justify-content-left">
              <div class="col-12">
              <h2 style="color:blue;"ß>Image Segmentation </h2>
            </div>
              <div class="col-12 col-md-12 col-lg-6 col-xl-6">
                  <h3>Image segmentation is the process of partitioning a digital image into multiple segments (sets of pixels, also known as image objects). The goal of segmentation is to simplify and/or change the representation of an image into something that is more meaningful and easier to analyze. Image segmentation is typically used to locate objects and boundaries (lines, curves, etc.) in images. More precisely, image segmentation is the process of assigning a label to every pixel in an image such that pixels with the same label share certain characteristics..</h3>
                <h3 style="color:blue;">Prerequisite skills: </h3>
              <h3>
                <ul>
                  <li>Basic programming knowledge in Python</li>
                  <li>Basic knowledge in Deep Learning</li>
                  <li>Ideal for students interested in Image Processing</li>
                </ul>
              </h3>
                </div>
                <div class="col-12 col-md-12 col-lg-6 col-xl-6">
                  <br>
                  <img class="img-fluid" src="assets/img/projects/UG_MSc/segmentation.jpg" alt="IMAGE PLACEHOLDER">
                </div>
              </div>
            </div>
        </div> -->




      <!-- ======= Project 3 ======= -->
      <!--
      <div class = "project-3">
        <div class="container project-container">
          <div class="row justify-content-left d-flex flex-wrap align-items-center">
            <div class="col-12 col-md-12 col-lg-6 col-xl-6">
            <img class="img-fluid" src="assets/img/projects/UG_MSc/TL.png" alt="TDI example strip">
            </div>
            <div class="col-12 col-md-12 col-lg-6 col-xl-6">
              <h2 style="color:blue;">Transfer Learning</h2>
              <h3>Transfer learning is a research problem in machine learning that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem. For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks. In this project, you will work on classifying images of cats and dogs by using transfer learning from a pre-trained network.
              </h3>
              <h3 style="color:blue;">Prerequisite skills: </h3>
              <h3>
                <ul>
                  <li>Basic programming knowledge in Python</li>
                  <li>Basic knowledge in Deep Learning</li>
                  <li>Ideal for students interested in Image Processing</li>
                </ul>
              </h3>
              <br>
            </div>
          </div>
        </div>
      </div> -->


          </section><!-- End project-body -->

      </main><!-- End #main -->

  <!-- ======= Footer - DONT CHANGE ======= -->
  <footer id="footer">

        <div class="footer-top">
            <div class="container">
                <div class="section-title">
                    <h2>Contact Details</h2>
                </div>
                <div class="row">
                    <div class="col-lg-3 col-md-6 footer-contact">
                        <p>
                            Professor Massoud Zolgharni <br>
                            Massoud.Zolgharni@uwl.ac.uk<br>
                        </p>
                    </div>
                    <div class="col-lg-2 col-md-6 footer-links">
                        <p>
                            Dr Nasim Dadashi <br>
                            nasim.dadashiserej@uwl.ac.uk<br>
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <div class="container d-md-flex py-4">
            <div class="me-md-auto text-center text-md-start">
                <div class="copyright">
                    &copy; Copyright <strong><span>IntSaV</span></strong>. All Rights Reserved
                </div>
            </div>
            <div class="social-links text-center text-md-right pt-3 pt-md-0">
                <a href="https://twitter.com/intsav_?lang=en-gb" target="_blank" rel="noopener noreferrer" class="twitter"><i class="bx bxl-twitter"></i></a>
                <a href="https://www.linkedin.com/company/intelligent-sensing-and-vision-research-group-intsav" target="_blank" rel="noopener noreferrer"><i class="bi bi-linkedin"></i></a>
            </div>
        </div>
  </footer><!-- End Footer -->

  <div id="preloader"></div>
  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/purecounter/purecounter.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>